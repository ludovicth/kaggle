{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('test_images', (10000, 28, 28), 'uint8')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_test ='C:\\Users\\Ludovic\\Documents\\CS289\\hw6\\hw6\\dataset\\\\test.mat'\n",
    "test = sio.loadmat(file_test)\n",
    "sio.whosmat(file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('train_images', (28, 28, 60000), 'double'),\n",
       " ('train_labels', (60000, 1), 'double')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_train ='C:\\Users\\Ludovic\\Documents\\CS289\\hw6\\hw6\\dataset\\\\train.mat'\n",
    "train = sio.loadmat(file_train)\n",
    "sio.whosmat(file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a05b828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = test['test_images'].copy()\n",
    "X = train['train_images'].copy()\n",
    "y = train['train_labels'].copy()\n",
    "\n",
    "plt.imshow(X_test[100,:,:])\n",
    "plt.show()\n",
    "\n",
    "X = X.swapaxes(0,2)\n",
    "X = X.swapaxes(1,2)\n",
    "X = X.reshape(60000,-1)\n",
    "X_test = X_test.reshape(10000, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype uint8 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype uint8 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X = scale(X, axis=1)\n",
    "X_test = scale(X_test, axis=1)\n",
    "X,y = shuffle(X,y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into training/validation set. add column of 1 for intercept\n",
    "X_train = X[:5*len(y)/6]\n",
    "y_train = y[:5*len(y)/6]\n",
    "X_val = X[5*len(y)/6:]\n",
    "y_val = y[5*len(y)/6:]\n",
    "X_train = np.hstack((X_train,np.ones(len(X_train)).reshape(-1,1)))\n",
    "X_val = np.hstack((X_val,np.ones(len(X_val)).reshape(-1,1)))\n",
    "X_test = np.hstack((X_test,np.ones(len(X_test)).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000L, 785L)\n",
      "(10000L, 785L)\n",
      "(10000L, 785L)\n",
      "(50000L, 1L)\n",
      "(60000L, 784L)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_val.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array([[1,2,3],[1,2,3]])\n",
    "z = np.array([1,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [3]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_numerical_gradient(N,X,y):\n",
    "    param_initial = N.get_params()\n",
    "    numgrad = np.zeros(param_initial.shape)\n",
    "    perturb = np.zeros(param_initial.shape)\n",
    "    print numgrad.shape\n",
    "    e = 1e-4\n",
    "\n",
    "    print \"param_initial \", param_initial, len(param_initial)   \n",
    "    \n",
    "    for p in xrange(len(perturb)-2, len(perturb)):\n",
    "        # set perturbation vector\n",
    "        print p\n",
    "        perturb[p] = e\n",
    "        N.set_params(param_initial + perturb)\n",
    "       \n",
    "        a2= N.forward(X)\n",
    "        b2 = N.one_hot(y)\n",
    "        #print type(a), a.shape\n",
    "        #print \"MSE\", MSE(a2[0], b2.iloc[0]) , \"shape a2[0]\", a2[0].shape, \"shape b2.iloc[0]\", b2.iloc[0].shape\n",
    "        \n",
    "        loss2 = np.sum([MSE(a2[i], b2.iloc[i]) for i in xrange(a2.shape[0])])\n",
    "        print \"loss2\", loss2\n",
    "\n",
    "        N.set_params(param_initial - perturb)\n",
    "\n",
    "        a1= N.forward(X)\n",
    "\n",
    "        b1 = N.one_hot(y)\n",
    "        loss1 = np.sum([MSE(a1[i], b1.iloc[i]) for i in xrange(a1.shape[0])])\n",
    "        print \"loss1\", loss1\n",
    "\n",
    "        #print \" a2 != a1?\", np.sum(a2 != a1)\n",
    "        # compute numerical gradient\n",
    "        numgrad[p] = (loss2-loss1)/(2*e)\n",
    "        \n",
    "        # return the value we changed back to zero\n",
    "        perturb[p] = 0\n",
    "    \n",
    "    # return params to original value\n",
    "    N.set_params(param_initial)\n",
    "        \n",
    "    return numgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(y):\n",
    "    '''\n",
    "    Input: vector\n",
    "    Returns: one-hot encoding\n",
    "    '''\n",
    "    return pd.get_dummies(y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hot = one_hot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self, learning_rate, epochs):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.n_in = 784\n",
    "        #self.n_in = images.shape[1]\n",
    "        self.n_hid = 200\n",
    "        self.n_out = 10\n",
    "        #self.n_out = len(np.unique(labels))\n",
    "        self.V = 0.1*np.random.rand(self.n_hid,self.n_in+1)\n",
    "        self.W = 0.1*np.random.rand(self.n_out,self.n_hid + 1)\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        # apply sigmoid activation function\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoid_prime(self,z):\n",
    "        # derivative of sigmoid function\n",
    "        g = self.sigmoid(z)\n",
    "        return np.multiply(g, 1-g)\n",
    "    \n",
    "    def tanh_prime(self,z):\n",
    "        # derivative fo tanh function\n",
    "        return 1 - np.tanh(z)**2\n",
    "    \n",
    "    def MSE(self,y):\n",
    "        '''\n",
    "        Mean-squared error function\n",
    "        y: vector, length n_out, ground truth label\n",
    "        z: vector, length n_out, z_k = value of k-th unit of output layer\n",
    "        '''\n",
    "        return .5*np.sum(np.square(np.linalg.norm(y - self.y_hat)))\n",
    "\n",
    "    def CEE(self,y):\n",
    "        '''\n",
    "        Cross-entropy error function\n",
    "        y: vector, length n_out, ground truth label\n",
    "        z: vector, length n_out, z_k = value of k-th unit of output layer\n",
    "        '''\n",
    "        #return sum(-(np.multiply(y,np.log(self.y_hat)) + np.multiply(1.0-y, np.log(1.0-self.y_hat))))\n",
    "        return -sum(y*np.log(self.y_hat) + (1-y)*np.log(1-self.y_hat))\n",
    "    \n",
    "    #def forward(self, X):\n",
    "    #    #propagate inputs through network\n",
    "    #    self.VX = np.dot(X,self.V.T)\n",
    "    #    self.h = np.tanh(self.VX)\n",
    "    #    \n",
    "    #    print \"h\",self.h.shape\n",
    "    #    print \"np.ones(self.h.shape[0]).reshape(-1,1)\", np.ones(self.h.shape[0]).reshape(-1,1).shape\n",
    "    #    self.h1 = np.vstack((self.h,np.ones(self.h.shape[1]).reshape(-1,1)))\n",
    "    #    \n",
    "    #    print \"h1\",self.h1.shape\n",
    "    #    \n",
    "    #    self.Wh = np.dot(self.h1,self.W.T)\n",
    "    #    self.y_hat = self.sigmoid(self.Wh)\n",
    "    #    \n",
    "    #    return self.y_hat\n",
    "    \n",
    "    def forward(self, X):\n",
    "        '''weights: trained weights, i.e. V;W\n",
    "        images: test set (features)\n",
    "        1. Compute labels of all images using the weights, V;W\n",
    "        2. return labels '''\n",
    "        \n",
    "        V = self.V\n",
    "        W = self.W\n",
    "\n",
    "        self.VX = np.dot(V, X.T)\n",
    "        self.h = np.tanh(self.VX)\n",
    "        if self.h.ndim>1:\n",
    "            self.h1 = np.vstack((self.h, np.ones(self.h.shape[1])))\n",
    "        else:\n",
    "            self.h1 = np.append(self.h, 1)\n",
    "        self.Wh = np.dot(W, self.h1)\n",
    "        self.y_hat = self.sigmoid(self.Wh).T \n",
    "        return self.y_hat\n",
    "    \n",
    "    \n",
    "    def MSE_prime(self, X, y):\n",
    "        '''\n",
    "        Cost function : Mean Squared Error\n",
    "        compute derivative with respect to V and W\n",
    "        \n",
    "        Input:\n",
    "        -----------------------------------------\n",
    "        X: vector size 784\n",
    "        y: vector size 10 (one hot encoded)\n",
    "        \n",
    "        Return: dJ/dV, dJ/dW\n",
    "        '''\n",
    "        \n",
    "        self.y_hat = self.forward(X)\n",
    "        delta3 = np.multiply((-(y-self.y_hat)), self.sigmoid_prime(self.Wh))\n",
    "        \n",
    "        dJdW = np.dot(self.h1.reshape(self.h1.shape[0],1),  delta3.reshape(delta3.shape[0],1).T).T       # shape dJdW (10L,201L)\n",
    "        delta1 = np.dot(delta3, self.W)\n",
    "        delta1 = np.delete(delta1, 200) # delete last column\n",
    "        \n",
    "        tmp = self.tanh_prime(self.VX)\n",
    "        delta2 = np.multiply(delta1,tmp)\n",
    "        dJdV = np.dot(X.reshape(X.shape[0],1), delta2.reshape(delta2.shape[0],1).T).T\n",
    "        return dJdV, dJdW\n",
    "    \n",
    "    def CEE_prime(self, X, y):\n",
    "        '''\n",
    "        Cost function : Cross-entropy error\n",
    "        compute derivative with respect to V and W\n",
    "        \n",
    "        Input:\n",
    "        -----------------------------------------\n",
    "        X: vector size 784\n",
    "        y: vector size 10 (one hot encoded)\n",
    "        \n",
    "        Return: dJ/dV, dJ/dW\n",
    "        '''\n",
    "        \n",
    "        self.y_hat = self.forward(X)\n",
    "        delta3 = -(y-self.y_hat)\n",
    "        \n",
    "        dJdW = np.dot(self.h1.reshape(self.h1.shape[0],1),  delta3.reshape(delta3.shape[0],1).T).T       # shape dJdW (10L,201L)\n",
    "        delta1 = np.dot(delta3, self.W)\n",
    "        delta1 = np.delete(delta1, 200) # delete last column\n",
    "        \n",
    "        tmp = self.tanh_prime(self.VX)\n",
    "        delta2 = np.multiply(delta1,tmp)\n",
    "        dJdV = np.dot(X.reshape(X.shape[0],1), delta2.reshape(delta2.shape[0],1).T).T\n",
    "        return dJdV, dJdW\n",
    "        \n",
    "    def train(self,images, labels, cost_function):\n",
    "        '''\n",
    "        Train dat neural net\n",
    "        \n",
    "        Input:\n",
    "        --------------------------------------------\n",
    "        images: array-like n_samples x n_in , training instances\n",
    "        labels: vector size n_samples, target labels\n",
    "        cost_function: 'MSE' (mean squared error) or 'CEE' (cross entropy)   \n",
    "        \n",
    "        Returns:\n",
    "        --------------------------------------------\n",
    "        self\n",
    "        '''        \n",
    "        start = time.time()\n",
    "        # store costs\n",
    "        self.cost = []\n",
    "        \n",
    "        self.pred_train = []\n",
    "        self.pred_val =[]\n",
    "        count = 0\n",
    "        \n",
    "        if cost_function == \"MSE\":\n",
    "            for e in xrange(self.epochs):\n",
    "                if e>=1:\n",
    "                    tmp = time.time()\n",
    "                    print \"epoch\",e, \"latest validation accuracy\", self.pred_val[-1], \"Time elapsed\", tmp-start\n",
    "                X,y = shuffle(images,labels)\n",
    "\n",
    "                for i in xrange(X.shape[0]):\n",
    "                    self.train_MSE(X[i],y.iloc[i])\n",
    "                    count += 1\n",
    "\n",
    "                    if count%1000 == 0:\n",
    "                        self.forward(images)                \n",
    "                        J = self.MSE(labels)\n",
    "                        self.cost.append(J)\n",
    "\n",
    "                        pred_train = self.predict(X_train)\n",
    "                        predictions_train = []\n",
    "                        for i in xrange(pred_train.shape[0]):\n",
    "                            predictions_train.append(np.argmax(pred_train[i]))\n",
    "                        acc_train = np.sum(predictions_train == y_train.ravel())/float(len(y_train.ravel()))\n",
    "                        #print \"accuracy train\", acc_train\n",
    "                        self.pred_train.append(acc_train)\n",
    "\n",
    "                        pred_val = self.predict(X_val)\n",
    "                        predictions_val = []\n",
    "                        for i in xrange(pred_val.shape[0]):\n",
    "                            predictions_val.append(np.argmax(pred_val[i]))\n",
    "                        acc_val = np.sum(predictions_val == y_val.ravel())/float(len(y_val.ravel()))\n",
    "                        #print \"accuracy val\", acc_val\n",
    "                        self.pred_val.append(acc_val)\n",
    "        elif cost_function == \"CEE\":\n",
    "            for e in xrange(self.epochs):\n",
    "                if e>=1:\n",
    "                    tmp = time.time()\n",
    "                    print \"epoch\",e, \"latest validation accuracy\", self.pred_val[-1], \"Time elapsed\", tmp-start\n",
    "                X,y = shuffle(images,labels)\n",
    "\n",
    "                for i in xrange(X.shape[0]):\n",
    "                    self.train_CEE(X[i],y.iloc[i])\n",
    "                    count += 1\n",
    "\n",
    "                    if count%1000 == 0:\n",
    "                        self.forward(images)                \n",
    "                        J = self.CEE(labels)\n",
    "                        self.cost.append(J)\n",
    "\n",
    "                        pred_train = self.predict(X_train)\n",
    "                        predictions_train = []\n",
    "                        for i in xrange(pred_train.shape[0]):\n",
    "                            predictions_train.append(np.argmax(pred_train[i]))\n",
    "                        acc_train = np.sum(predictions_train == y_train.ravel())/float(len(y_train.ravel()))\n",
    "                        #print \"accuracy train\", acc_train\n",
    "                        self.pred_train.append(acc_train)\n",
    "\n",
    "                        pred_val = self.predict(X_val)\n",
    "                        predictions_val = []\n",
    "                        for i in xrange(pred_val.shape[0]):\n",
    "                            predictions_val.append(np.argmax(pred_val[i]))\n",
    "                        acc_val = np.sum(predictions_val == y_val.ravel())/float(len(y_val.ravel()))\n",
    "                        #print \"accuracy val\", acc_val\n",
    "                        self.pred_val.append(acc_val)\n",
    "        else:\n",
    "            print \"Cost function not available\"\n",
    "    \n",
    "    \n",
    "    def train_MSE(self,images, labels):\n",
    "        djdv, djdw = self.MSE_prime(images,labels)\n",
    "        self.W -= self.learning_rate*djdw\n",
    "        self.V -= self.learning_rate*djdv\n",
    "    \n",
    "    def train_CEE(self,images, labels):\n",
    "        djdv, djdw = self.CEE_prime(images,labels)\n",
    "        self.W -= self.learning_rate*djdw\n",
    "        self.V -= self.learning_rate*djdv\n",
    "    \n",
    "    \n",
    "    def predict(self, images):\n",
    "        self.forward(images)\n",
    "        return self.y_hat\n",
    "        \n",
    "    def get_params(self):\n",
    "        # get V and W rolled into vector\n",
    "        params = np.concatenate((self.V.ravel(), self.W.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        # set V and W using single parameter vector\n",
    "        V_start = 0\n",
    "        V_end = self.n_hid*self.n_in\n",
    "        self.V = np.reshape(params[V_start:V_end], \\\n",
    "                           (self.n_hid, self.n_in))\n",
    "        W_end = V_end+ self.n_hid*self.n_out\n",
    "        self.W = np.reshape(params[V_end:],\\\n",
    "                           (self.n_out,self.n_hid))\n",
    "        \n",
    "    def compute_gradients(self,X,y):\n",
    "        dJdV, dJdW = self.cost_function_prime(X,y)\n",
    "        return np.concatenate((dJdV.ravel(), dJdW.ravel()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 latest validation accuracy 0.9507 Time elapsed 236.194999933\n",
      "epoch 2 latest validation accuracy 0.9596 Time elapsed 472.459000111\n",
      "epoch 3 latest validation accuracy 0.9605 Time elapsed 708.045000076\n",
      "epoch 4 latest validation accuracy 0.9577 Time elapsed 945.27699995\n",
      "epoch 5 latest validation accuracy 0.9638 Time elapsed 1182.03299999\n",
      "epoch 6 latest validation accuracy 0.9627 Time elapsed 1418.60500002\n",
      "epoch 7 latest validation accuracy 0.9668 Time elapsed 1657.00699997\n",
      "epoch 8 latest validation accuracy 0.9677 Time elapsed 1897.07500005\n",
      "epoch 9 latest validation accuracy 0.9656 Time elapsed 2136.50399995\n",
      "epoch 10 latest validation accuracy 0.9691 Time elapsed 2371.30200005\n",
      "epoch 11 latest validation accuracy 0.9701 Time elapsed 2605.63199997\n",
      "epoch 12 latest validation accuracy 0.9681 Time elapsed 2843.53999996\n",
      "epoch 13 latest validation accuracy 0.9693 Time elapsed 3095.05900002\n",
      "epoch 14 latest validation accuracy 0.9699 Time elapsed 3334.95600009\n",
      "epoch 15 latest validation accuracy 0.969 Time elapsed 3588.96700001\n",
      "epoch 16 latest validation accuracy 0.973 Time elapsed 3836.62400007\n",
      "epoch 17 latest validation accuracy 0.971 Time elapsed 4161.53800011\n",
      "epoch 18 latest validation accuracy 0.9727 Time elapsed 4370.875\n",
      "epoch 19 latest validation accuracy 0.9732 Time elapsed 4573.14300013\n",
      "epoch 20 latest validation accuracy 0.9737 Time elapsed 4775.75500011\n",
      "epoch 21 latest validation accuracy 0.9738 Time elapsed 4976.4749999\n",
      "epoch 22 latest validation accuracy 0.9739 Time elapsed 5199.87000012\n",
      "epoch 23 latest validation accuracy 0.974 Time elapsed 5413.9289999\n",
      "epoch 24 latest validation accuracy 0.974 Time elapsed 5619.57599998\n",
      "epoch 25 latest validation accuracy 0.9741 Time elapsed 5828.55500007\n",
      "epoch 26 latest validation accuracy 0.9738 Time elapsed 6033.98900008\n",
      "epoch 27 latest validation accuracy 0.9741 Time elapsed 6240.16300011\n",
      "epoch 28 latest validation accuracy 0.9739 Time elapsed 6445.65899992\n",
      "epoch 29 latest validation accuracy 0.974 Time elapsed 6652.56699991\n",
      "Total duration 6863.6559999\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "NN_CEE = Neural_Network(0.01,30)\n",
    "NN_CEE.train(X_train,y_hot,\"CEE\")\n",
    "end = time.time()\n",
    "print \"Total duration\",end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(NN_CEE.pred_train, color = 'red')\n",
    "plt.plot(NN_CEE.pred_val, color = 'blue')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['training set','validation set'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 latest validation accuracy 0.9506 Time elapsed 235.198999882\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-9cb9dbb4de37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mNN_CEE2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeural_Network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mNN_CEE2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_hot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"CEE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Total duration\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-147-d4d2f43a6db4>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, images, labels, cost_function)\u001b[0m\n\u001b[0;32m    196\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m                         \u001b[0mpred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m                         \u001b[0mpredictions_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-147-d4d2f43a6db4>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-147-d4d2f43a6db4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "NN_CEE2 = Neural_Network(0.01,30)\n",
    "NN_CEE2.train(X_train,y_hot,\"CEE\")\n",
    "end = time.time()\n",
    "print \"Total duration\",end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(NN_CEE2.cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 latest validation accuracy 0.9536\n",
      "epoch 3 latest validation accuracy 0.9627\n",
      "epoch 4 latest validation accuracy 0.9666\n",
      "epoch 5 latest validation accuracy 0.9704\n",
      "epoch 6 latest validation accuracy 0.9692\n",
      "epoch 7 latest validation accuracy 0.9712\n",
      "epoch 8 latest validation accuracy 0.9711\n",
      "epoch 9 latest validation accuracy 0.9726\n",
      "epoch 10 latest validation accuracy 0.9738\n",
      "epoch 11 latest validation accuracy 0.9737\n",
      "epoch 12 latest validation accuracy 0.9726\n",
      "epoch 13 latest validation accuracy 0.9744\n",
      "epoch 14 latest validation accuracy 0.9736\n",
      "epoch 15 latest validation accuracy 0.9726\n",
      "epoch 16 latest validation accuracy 0.9732\n",
      "epoch 17 latest validation accuracy 0.9735\n",
      "epoch 18 latest validation accuracy 0.9752\n",
      "epoch 19 latest validation accuracy 0.9742\n",
      "epoch 20 latest validation accuracy 0.9744\n",
      "epoch 21 latest validation accuracy 0.9741\n",
      "epoch 22 latest validation accuracy 0.9738\n",
      "epoch 23 latest validation accuracy 0.9747\n",
      "epoch 24 latest validation accuracy 0.9748\n",
      "epoch 25 latest validation accuracy 0.9742\n",
      "epoch 26 latest validation accuracy 0.975\n",
      "epoch 27 latest validation accuracy 0.9751\n",
      "epoch 28 latest validation accuracy 0.9746\n",
      "epoch 29 latest validation accuracy 0.9747\n",
      "epoch 30 latest validation accuracy 0.9746\n",
      "epoch 31 latest validation accuracy 0.9753\n",
      "epoch 32 latest validation accuracy 0.9752\n",
      "epoch 33 latest validation accuracy 0.975\n",
      "epoch 34 latest validation accuracy 0.9757\n"
     ]
    }
   ],
   "source": [
    "foo = Neural_Network(0.01,35)\n",
    "foo.train(X_train,y_hot,\"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 latest validation accuracy 0.9206 Time elapsed 252.832999945\n",
      "epoch 2 latest validation accuracy 0.9304 Time elapsed 504.828999996\n",
      "epoch 3 latest validation accuracy 0.9362 Time elapsed 769.933000088\n",
      "epoch 4 latest validation accuracy 0.9318 Time elapsed 1019.66799998\n"
     ]
    }
   ],
   "source": [
    "foo2 = Neural_Network(0.1,5)\n",
    "foo2.train(X_train,y_hot,\"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94579999999999997"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo2.pred_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 latest validation accuracy 0.9289\n",
      "epoch 3 latest validation accuracy 0.9419\n",
      "epoch 4 latest validation accuracy 0.9396\n",
      "epoch 5 latest validation accuracy 0.9444\n",
      "epoch 6 latest validation accuracy 0.9463\n",
      "epoch 7 latest validation accuracy 0.9518\n",
      "epoch 8 latest validation accuracy 0.9444\n",
      "epoch 9 latest validation accuracy 0.9482\n",
      "epoch 10 latest validation accuracy 0.9522\n",
      "epoch 11 latest validation accuracy 0.9486\n",
      "epoch 12 latest validation accuracy 0.9561\n",
      "epoch 13 latest validation accuracy 0.9546\n",
      "epoch 14 latest validation accuracy 0.9543\n",
      "epoch 15 latest validation accuracy 0.9571\n",
      "epoch 16 latest validation accuracy 0.9534\n",
      "epoch 17 latest validation accuracy 0.9546\n",
      "epoch 18 latest validation accuracy 0.9545\n",
      "epoch 19 latest validation accuracy 0.9528\n",
      "epoch 20 latest validation accuracy 0.9549\n",
      "epoch 21 latest validation accuracy 0.9605\n",
      "epoch 22 latest validation accuracy 0.9567\n",
      "epoch 23 latest validation accuracy 0.9589\n",
      "epoch 24 latest validation accuracy 0.9588\n",
      "epoch 25 latest validation accuracy 0.9596\n",
      "epoch 26 latest validation accuracy 0.9593\n",
      "epoch 27 latest validation accuracy 0.9596\n",
      "epoch 28 latest validation accuracy 0.9589\n",
      "epoch 29 latest validation accuracy 0.9582\n"
     ]
    }
   ],
   "source": [
    "bar = Neural_Network(0.1,30)\n",
    "bar.train(X_train,y_hot,\"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(foo.pred_train, color ='red')\n",
    "plt.plot(foo.pred_val)\n",
    "plt.xlabel('Number of iterations (x1000)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['training set','validation set'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(bar.pred_train, color ='red')\n",
    "plt.plot(bar.pred_val)\n",
    "plt.xlabel('Number of iterations (x1000)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['training set','validation set'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "1000 15432.3903288\n",
      "accuracy train 0.67112\n",
      "accuracy val 0.6649\n",
      "2000 11609.4480083\n",
      "accuracy train 0.75054\n",
      "accuracy val 0.7543\n",
      "3000 9764.58748916\n",
      "accuracy train 0.80682\n",
      "accuracy val 0.8082\n",
      "4000 8490.75897219\n",
      "accuracy train 0.82716\n",
      "accuracy val 0.8274\n",
      "5000 0.0\n",
      "accuracy train 0.8349\n",
      "accuracy val 0.8314\n",
      "6000 7187.55185216\n",
      "accuracy train 0.84648\n",
      "accuracy val 0.8468\n",
      "7000 0.0\n",
      "accuracy train 0.84664\n",
      "accuracy val 0.8439\n",
      "8000 6283.39306422\n",
      "accuracy train 0.85976\n",
      "accuracy val 0.8631\n",
      "9000 6024.5253787\n",
      "accuracy train 0.86454\n",
      "accuracy val 0.863\n",
      "10000 5811.60315051\n",
      "accuracy train 0.8702\n",
      "accuracy val 0.8677\n",
      "11000 5599.13523334\n",
      "accuracy train 0.87296\n",
      "accuracy val 0.8732\n",
      "12000 0.0\n",
      "accuracy train 0.8803\n",
      "accuracy val 0.8803\n",
      "13000 5253.4622225\n",
      "accuracy train 0.87882\n",
      "accuracy val 0.8779\n",
      "14000 5113.42605091\n",
      "accuracy train 0.88604\n",
      "accuracy val 0.8832\n",
      "15000 4896.64553852\n",
      "accuracy train 0.89012\n",
      "accuracy val 0.8885\n",
      "16000 4717.60661008\n",
      "accuracy train 0.8934\n",
      "accuracy val 0.8922\n",
      "17000 4700.80331668\n",
      "accuracy train 0.89382\n",
      "accuracy val 0.8921\n",
      "18000 4539.27192514\n",
      "accuracy train 0.8968\n",
      "accuracy val 0.8923\n",
      "19000 4408.20140946\n",
      "accuracy train 0.9004\n",
      "accuracy val 0.8959\n",
      "20000 4384.59000459\n",
      "accuracy train 0.89942\n",
      "accuracy val 0.8959\n",
      "21000 4225.99277005\n",
      "accuracy train 0.9045\n",
      "accuracy val 0.9004\n",
      "22000 4160.46446492\n",
      "accuracy train 0.90528\n",
      "accuracy val 0.9033\n",
      "23000 3992.98836349\n",
      "accuracy train 0.90928\n",
      "accuracy val 0.9065\n",
      "24000 4047.54718648\n",
      "accuracy train 0.9069\n",
      "accuracy val 0.9054\n",
      "25000 3881.38105745\n",
      "accuracy train 0.91124\n",
      "accuracy val 0.9094\n",
      "26000 0.0\n",
      "accuracy train 0.91126\n",
      "accuracy val 0.9086\n",
      "27000 3722.75414421\n",
      "accuracy train 0.91598\n",
      "accuracy val 0.9124\n",
      "28000 3709.62869404\n",
      "accuracy train 0.9165\n",
      "accuracy val 0.9113\n",
      "29000 3641.33293948\n",
      "accuracy train 0.91612\n",
      "accuracy val 0.913\n",
      "30000 3632.21279279\n",
      "accuracy train 0.91784\n",
      "accuracy val 0.9154\n",
      "31000 3669.65577941\n",
      "accuracy train 0.91686\n",
      "accuracy val 0.9112\n",
      "32000 3520.29650182\n",
      "accuracy train 0.92092\n",
      "accuracy val 0.9182\n",
      "33000 3460.57972697\n",
      "accuracy train 0.92342\n",
      "accuracy val 0.9202\n",
      "34000 3277.76040383\n",
      "accuracy train 0.92752\n",
      "accuracy val 0.9226\n",
      "35000 3314.73747534\n",
      "accuracy train 0.92658\n",
      "accuracy val 0.9222\n",
      "36000 0.0\n",
      "accuracy train 0.9276\n",
      "accuracy val 0.9234\n",
      "37000 3310.27147558\n",
      "accuracy train 0.92634\n",
      "accuracy val 0.9215\n",
      "38000 3178.04172869\n",
      "accuracy train 0.9294\n",
      "accuracy val 0.9261\n",
      "39000 3118.59171377\n",
      "accuracy train 0.93018\n",
      "accuracy val 0.9271\n",
      "40000 3100.97716985\n",
      "accuracy train 0.93134\n",
      "accuracy val 0.9281\n",
      "41000 3058.54857723\n",
      "accuracy train 0.93146\n",
      "accuracy val 0.9272\n",
      "42000 3082.980716\n",
      "accuracy train 0.93256\n",
      "accuracy val 0.9304\n",
      "43000 2996.68846434\n",
      "accuracy train 0.9349\n",
      "accuracy val 0.9311\n",
      "44000 2941.57301616\n",
      "accuracy train 0.93414\n",
      "accuracy val 0.9297\n",
      "45000 2894.06164941\n",
      "accuracy train 0.93674\n",
      "accuracy val 0.9325\n",
      "46000 2903.53423036\n",
      "accuracy train 0.93486\n",
      "accuracy val 0.9322\n",
      "47000 2939.06618716\n",
      "accuracy train 0.93348\n",
      "accuracy val 0.93\n",
      "48000 2797.13124433\n",
      "accuracy train 0.93822\n",
      "accuracy val 0.934\n",
      "49000 2764.95441802\n",
      "accuracy train 0.93772\n",
      "accuracy val 0.933\n",
      "50000 2824.73039862\n",
      "accuracy train 0.93764\n",
      "accuracy val 0.9323\n",
      "epoch 1\n",
      "51000 2783.1225802\n",
      "accuracy train 0.93848\n",
      "accuracy val 0.932\n",
      "52000 2692.01029659\n",
      "accuracy train 0.93992\n",
      "accuracy val 0.9351\n",
      "53000 2712.41241671\n",
      "accuracy train 0.93992\n",
      "accuracy val 0.9351\n",
      "54000 2691.05958209\n",
      "accuracy train 0.94084\n",
      "accuracy val 0.9354\n",
      "55000 2578.4912267\n",
      "accuracy train 0.94244\n",
      "accuracy val 0.9381\n",
      "56000 2626.81905048\n",
      "accuracy train 0.94118\n",
      "accuracy val 0.9366\n",
      "57000 2843.60078449\n",
      "accuracy train 0.93476\n",
      "accuracy val 0.9307\n",
      "58000 2512.44622753\n",
      "accuracy train 0.94532\n",
      "accuracy val 0.9406\n",
      "59000 2577.19265231\n",
      "accuracy train 0.94438\n",
      "accuracy val 0.9379\n",
      "60000 2564.17437275\n",
      "accuracy train 0.94446\n",
      "accuracy val 0.9366\n",
      "61000 2559.6665801\n",
      "accuracy train 0.94426\n",
      "accuracy val 0.9382\n",
      "62000 2498.59069099\n",
      "accuracy train 0.94546\n",
      "accuracy val 0.9384\n",
      "63000 2437.11572315\n",
      "accuracy train 0.94686\n",
      "accuracy val 0.9402\n",
      "64000 2364.65963268\n",
      "accuracy train 0.94778\n",
      "accuracy val 0.9434\n",
      "65000 2416.74570088\n",
      "accuracy train 0.94694\n",
      "accuracy val 0.9398\n",
      "66000 2406.34560175\n",
      "accuracy train 0.94654\n",
      "accuracy val 0.94\n",
      "67000 0.0\n",
      "accuracy train 0.95046\n",
      "accuracy val 0.9426\n",
      "68000 2406.22900148\n",
      "accuracy train 0.94782\n",
      "accuracy val 0.9421\n",
      "69000 2290.37893292\n",
      "accuracy train 0.95002\n",
      "accuracy val 0.9441\n",
      "70000 2258.27487117\n",
      "accuracy train 0.95082\n",
      "accuracy val 0.9445\n",
      "71000 2257.17746809\n",
      "accuracy train 0.95108\n",
      "accuracy val 0.9437\n",
      "72000 2209.6416108\n",
      "accuracy train 0.9526\n",
      "accuracy val 0.9443\n",
      "73000 2197.72869186\n",
      "accuracy train 0.95186\n",
      "accuracy val 0.9458\n",
      "74000 2266.54094657\n",
      "accuracy train 0.95096\n",
      "accuracy val 0.9427\n",
      "75000 2211.02705778\n",
      "accuracy train 0.9521\n",
      "accuracy val 0.9448\n",
      "76000 2129.74630588\n",
      "accuracy train 0.95404\n",
      "accuracy val 0.9467\n",
      "77000 2186.12153811\n",
      "accuracy train 0.95374\n",
      "accuracy val 0.9482\n",
      "78000 2084.8455638\n",
      "accuracy train 0.95552\n",
      "accuracy val 0.9494\n",
      "79000 2083.53405484\n",
      "accuracy train 0.9562\n",
      "accuracy val 0.9495\n",
      "80000 2138.03656119\n",
      "accuracy train 0.9543\n",
      "accuracy val 0.9477\n",
      "81000 2070.11911916\n",
      "accuracy train 0.95614\n",
      "accuracy val 0.9488\n",
      "82000 2114.35490741\n",
      "accuracy train 0.95484\n",
      "accuracy val 0.9471\n",
      "83000 2092.12370202\n",
      "accuracy train 0.95596\n",
      "accuracy val 0.9473\n",
      "84000 2145.66408791\n",
      "accuracy train 0.9564\n",
      "accuracy val 0.9467\n",
      "85000 2038.59813441\n",
      "accuracy train 0.95762\n",
      "accuracy val 0.9467\n",
      "86000 2037.55899578\n",
      "accuracy train 0.95674\n",
      "accuracy val 0.9484\n",
      "87000 1996.63724399\n",
      "accuracy train 0.95778\n",
      "accuracy val 0.9496\n",
      "88000 1980.27291206\n",
      "accuracy train 0.9578\n",
      "accuracy val 0.951\n",
      "89000 1973.07741642\n",
      "accuracy train 0.9586\n",
      "accuracy val 0.9508\n",
      "90000 1889.53134512\n",
      "accuracy train 0.96008\n",
      "accuracy val 0.9529\n",
      "91000 0.0\n",
      "accuracy train 0.95798\n",
      "accuracy val 0.9505\n",
      "92000 1927.96828411\n",
      "accuracy train 0.9599\n",
      "accuracy val 0.9516\n",
      "93000 1896.99777905\n",
      "accuracy train 0.95912\n",
      "accuracy val 0.9539\n",
      "94000 1942.21743323\n",
      "accuracy train 0.95998\n",
      "accuracy val 0.9524\n",
      "95000 1845.20021226\n",
      "accuracy train 0.96192\n",
      "accuracy val 0.9532\n",
      "96000 1890.45490403\n",
      "accuracy train 0.96056\n",
      "accuracy val 0.9515\n",
      "97000 1924.30699885\n",
      "accuracy train 0.9609\n",
      "accuracy val 0.9523\n",
      "98000 1813.94432172\n",
      "accuracy train 0.96256\n",
      "accuracy val 0.9548\n",
      "99000 1799.05678117\n",
      "accuracy train 0.96294\n",
      "accuracy val 0.9539\n",
      "100000 1789.05559827\n",
      "accuracy train 0.9624\n",
      "accuracy val 0.9542\n",
      "epoch 2\n",
      "101000 1758.56219904\n",
      "accuracy train 0.96352\n",
      "accuracy val 0.9552\n",
      "102000 1793.86063446\n",
      "accuracy train 0.962\n",
      "accuracy val 0.9546\n",
      "103000 1741.21927826\n",
      "accuracy train 0.96468\n",
      "accuracy val 0.9556\n",
      "104000 1762.70968735\n",
      "accuracy train 0.96378\n",
      "accuracy val 0.9557\n",
      "105000 1756.48213061\n",
      "accuracy train 0.96322\n",
      "accuracy val 0.9545\n",
      "106000 1750.01881861\n",
      "accuracy train 0.9644\n",
      "accuracy val 0.9551\n",
      "107000 1752.53320562\n",
      "accuracy train 0.96476\n",
      "accuracy val 0.9551\n",
      "108000 1700.40659236\n",
      "accuracy train 0.96506\n",
      "accuracy val 0.9556\n",
      "109000 1733.59970679\n",
      "accuracy train 0.96458\n",
      "accuracy val 0.9544\n",
      "110000 1704.75107788\n",
      "accuracy train 0.96408\n",
      "accuracy val 0.9563\n",
      "111000 1728.50089088\n",
      "accuracy train 0.96462\n",
      "accuracy val 0.9549\n",
      "112000 1671.38202283\n",
      "accuracy train 0.96554\n",
      "accuracy val 0.956\n",
      "113000 1663.46583809\n",
      "accuracy train 0.96558\n",
      "accuracy val 0.9568\n",
      "114000 1675.33515395\n",
      "accuracy train 0.96478\n",
      "accuracy val 0.956\n",
      "115000 1664.19134179\n",
      "accuracy train 0.96608\n",
      "accuracy val 0.9567\n",
      "116000 1642.01586058\n",
      "accuracy train 0.9669\n",
      "accuracy val 0.9576\n",
      "117000 1639.55033364\n",
      "accuracy train 0.96676\n",
      "accuracy val 0.9568\n",
      "118000 1582.6500569\n",
      "accuracy train 0.96812\n",
      "accuracy val 0.9588\n",
      "119000 1608.62355736\n",
      "accuracy train 0.96712\n",
      "accuracy val 0.9582\n",
      "120000 1615.76388595\n",
      "accuracy train 0.96822\n",
      "accuracy val 0.9588\n",
      "121000 1600.71577998\n",
      "accuracy train 0.9674\n",
      "accuracy val 0.958\n",
      "122000 1552.99791001\n",
      "accuracy train 0.96844\n",
      "accuracy val 0.9589\n",
      "123000 1563.45941346\n",
      "accuracy train 0.9684\n",
      "accuracy val 0.9583\n",
      "124000 1556.94052819\n",
      "accuracy train 0.96864\n",
      "accuracy val 0.9588\n",
      "125000 1581.92324897\n",
      "accuracy train 0.96804\n",
      "accuracy val 0.9596\n",
      "126000 1595.52844758\n",
      "accuracy train 0.96796\n",
      "accuracy val 0.9581\n",
      "127000 1515.8503212\n",
      "accuracy train 0.96872\n",
      "accuracy val 0.9602\n",
      "128000 1526.24166771\n",
      "accuracy train 0.96942\n",
      "accuracy val 0.9601\n",
      "129000 1509.62463408\n",
      "accuracy train 0.96956\n",
      "accuracy val 0.9592\n",
      "130000 1525.69059994\n",
      "accuracy train 0.96816\n",
      "accuracy val 0.9601\n",
      "131000 1520.9820115\n",
      "accuracy train 0.96962\n",
      "accuracy val 0.9594\n",
      "132000 1530.63962947\n",
      "accuracy train 0.96886\n",
      "accuracy val 0.9597\n",
      "133000 0.0\n",
      "accuracy train 0.97054\n",
      "accuracy val 0.9601\n",
      "134000 1472.84564871\n",
      "accuracy train 0.97006\n",
      "accuracy val 0.9595\n",
      "135000 1429.07863227\n",
      "accuracy train 0.97098\n",
      "accuracy val 0.9614\n",
      "136000 1474.18668203\n",
      "accuracy train 0.97052\n",
      "accuracy val 0.96\n",
      "137000 1465.53573441\n",
      "accuracy train 0.97108\n",
      "accuracy val 0.9601\n",
      "138000 1423.40698476\n",
      "accuracy train 0.97132\n",
      "accuracy val 0.9604\n",
      "139000 1400.46067624\n",
      "accuracy train 0.97162\n",
      "accuracy val 0.96\n",
      "140000 1435.28797688\n",
      "accuracy train 0.97118\n",
      "accuracy val 0.9605\n",
      "141000 1436.81298135\n",
      "accuracy train 0.97212\n",
      "accuracy val 0.9618\n",
      "142000 1454.62301813\n",
      "accuracy train 0.9718\n",
      "accuracy val 0.9609\n",
      "143000 1441.86781457\n",
      "accuracy train 0.97134\n",
      "accuracy val 0.9604\n",
      "144000 1457.8987597\n",
      "accuracy train 0.97068\n",
      "accuracy val 0.96\n",
      "145000 1382.93037317\n",
      "accuracy train 0.97246\n",
      "accuracy val 0.961\n",
      "146000 1388.15338989\n",
      "accuracy train 0.97202\n",
      "accuracy val 0.9611\n",
      "147000 1394.50775405\n",
      "accuracy train 0.97218\n",
      "accuracy val 0.9608\n",
      "148000 1394.83568983\n",
      "accuracy train 0.97218\n",
      "accuracy val 0.9611\n",
      "149000 1383.41918903\n",
      "accuracy train 0.97264\n",
      "accuracy val 0.9629\n",
      "150000 1365.50522819\n",
      "accuracy train 0.97374\n",
      "accuracy val 0.9616\n",
      "epoch 3\n",
      "151000 1333.07620406\n",
      "accuracy train 0.97362\n",
      "accuracy val 0.9629\n",
      "152000 1308.97201464\n",
      "accuracy train 0.97402\n",
      "accuracy val 0.963\n",
      "153000 1326.69452474\n",
      "accuracy train 0.97358\n",
      "accuracy val 0.9637\n",
      "154000 1332.58277839\n",
      "accuracy train 0.97386\n",
      "accuracy val 0.9634\n",
      "155000 1328.29067897\n",
      "accuracy train 0.97372\n",
      "accuracy val 0.9631\n",
      "156000 1309.22887954\n",
      "accuracy train 0.97514\n",
      "accuracy val 0.963\n",
      "157000 1298.97738783\n",
      "accuracy train 0.9749\n",
      "accuracy val 0.9642\n",
      "158000 1270.10209645\n",
      "accuracy train 0.97528\n",
      "accuracy val 0.9634\n",
      "159000 1364.4839745\n",
      "accuracy train 0.97416\n",
      "accuracy val 0.9637\n",
      "160000 1288.26585076\n",
      "accuracy train 0.97476\n",
      "accuracy val 0.964\n",
      "161000 1268.15094465\n",
      "accuracy train 0.97468\n",
      "accuracy val 0.9636\n",
      "162000 1289.04152918\n",
      "accuracy train 0.97532\n",
      "accuracy val 0.9643\n",
      "163000 1326.75517928\n",
      "accuracy train 0.97332\n",
      "accuracy val 0.9633\n",
      "164000 1304.71946715\n",
      "accuracy train 0.974\n",
      "accuracy val 0.9639\n",
      "165000 1248.55597595\n",
      "accuracy train 0.97546\n",
      "accuracy val 0.9648\n",
      "166000 1267.90934174\n",
      "accuracy train 0.97484\n",
      "accuracy val 0.9634\n",
      "167000 1236.74523135\n",
      "accuracy train 0.97624\n",
      "accuracy val 0.9642\n",
      "168000 1263.48136423\n",
      "accuracy train 0.97504\n",
      "accuracy val 0.9634\n",
      "169000 1228.76230498\n",
      "accuracy train 0.97634\n",
      "accuracy val 0.9641\n",
      "170000 1215.54727326\n",
      "accuracy train 0.97656\n",
      "accuracy val 0.9655\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-a52dff21eb98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeural_Network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_hot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-71-3db4728adb75>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, images, labels, cost_function)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_MSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-3db4728adb75>\u001b[0m in \u001b[0;36mtrain_MSE\u001b[1;34m(self, images, labels)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_MSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mdjdv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdjdw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSE_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdjdw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdjdv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-3db4728adb75>\u001b[0m in \u001b[0;36mMSE_prime\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mdelta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mdJdV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[1;31m#dJdV = np.dot(X.T, delta2).T   # shape      (10L, 201L)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdJdV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdJdW\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NN = Neural_Network(0.01,35)\n",
    "NN.train(X_train,y_hot,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99726\n",
      "0.97168\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print foo.pred_train[-1]\n",
    "print bar.pred_train[-1]\n",
    "print NN_CEE.pred_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(bar.cost, color ='red')\n",
    "plt.xlabel('Number of iterations (x1000)')\n",
    "plt.ylabel('Total cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(NN_CEE.cost, color ='red')\n",
    "plt.xlabel('Number of iterations (x1000)')\n",
    "plt.ylabel('Total cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_test = NN.predict(X_test)\n",
    "predictions_test = []\n",
    "for i in xrange(pred_test.shape[0]):\n",
    "    predictions_test.append(np.argmax(pred_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "#export result for kaggle submission\n",
    "output = open(\"predictions2.csv\", 'wb')\n",
    "output = csv.writer(output)\n",
    "output.writerow(('Id', 'Category'))\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    output.writerow((i+1, predictions_test[i]))\n",
    "#output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test2 = foo.predict(X_test)\n",
    "predictions_test2 = []\n",
    "for i in xrange(pred_test2.shape[0]):\n",
    "    predictions_test2.append(np.argmax(pred_test2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "#export result for kaggle submission\n",
    "output = open(\"predictions3.csv\", 'wb')\n",
    "output = csv.writer(output)\n",
    "output.writerow(('Id', 'Category'))\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    output.writerow((i+1, predictions_test2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test3 = NN_CEE.predict(X_test)\n",
    "predictions_test3 = []\n",
    "for i in xrange(pred_test3.shape[0]):\n",
    "    predictions_test3.append(np.argmax(pred_test3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export result for kaggle submission\n",
    "output = open(\"predictions4.csv\", 'wb')\n",
    "output = csv.writer(output)\n",
    "output.writerow(('Id', 'Category'))\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    output.writerow((i+1, predictions_test3[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
